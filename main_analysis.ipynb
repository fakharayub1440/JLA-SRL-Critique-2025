{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7/M3Pu0x15vvlpORSZq5k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Replication Notebook for: \"Predictive Markers or Causal Levers?\"\n","\n","This Jupyter Notebook contains the complete Python code to reproduce all the analyses, tables, and figures presented in the paper *\"Predictive Markers or Causal Levers? A Methodological Critique of Self-Regulated Learning Proxies in Log Data.\"*\n","\n","The notebook is structured to follow the two-phase analytical pipeline described in the manuscript.\n","\n","### Required Libraries\n","To run this notebook, you will need the following Python libraries. The first code cell will handle their installation.\n","- `pandas` & `pyarrow` (for data handling)\n","- `numpy`\n","- `scikit-learn` (for data splitting and modeling)\n","- `factor_analyzer` (for EFA and Parallel Analysis)\n","- `matplotlib` & `seaborn` (for visualizations)\n","- `semopy` (for Confirmatory Factor Analysis)\n","- `EGAnet` (for Exploratory Graph Analysis)"],"metadata":{"id":"mYq4ao7u7IRj"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"i2N_muBc7Hkq","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1761813721136,"user_tz":-300,"elapsed":11311,"user":{"displayName":"Fakhar Ayub","userId":"05777624125242800779"}},"outputId":"c2f40eae-20f0-49f3-8daa-d6871432dd53"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: Could not find a version that satisfies the requirement EGAnet (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for EGAnet\u001b[0m\u001b[31m\n","\u001b[0m"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'factor_analyzer'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2930684505.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfactor_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor_analyzer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFactorAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msemopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'factor_analyzer'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# =============================================================================\n","# SECTION 1: SETUP, DATA LOADING, AND SPLITTING\n","# =============================================================================\n","\n","# -----------------------------------------------------------------------------\n","# 1.1: Import all necessary libraries\n","# -----------------------------------------------------------------------------\n","# Install all required packages first\n","!pip install pandas pyarrow scikit-learn factor_analyzer matplotlib seaborn semopy EGAnet -q\n","# Cell 1: Install all required packages\n","\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from factor_analyzer.factor_analyzer import FactorAnalyzer\n","import semopy\n","\n","# Set plot style for professional-looking figures\n","plt.style.use('seaborn-v0_8-whitegrid')\n","print(\"✅ All libraries installed and imported successfully.\")\n","\n","# -----------------------------------------------------------------------------\n","# 1.2: Load the single dataset\n","# -----------------------------------------------------------------------------\n","# This notebook assumes the 'srl_features_final.parquet' file is in a '/data/' subfolder.\n","# Make sure to upload the data file to the correct location.\n","try:\n","    df = pd.read_parquet('data/srl_features_final.parquet')\n","    print(\"✅ Dataset 'srl_features_final.parquet' loaded successfully.\")\n","    print(\"\\nDataset Dimensions:\", df.shape)\n","    print(\"\\nFirst 5 rows of the dataset:\")\n","    display(df.head())\n","except FileNotFoundError:\n","    print(\"❌ ERROR: 'data/srl_features_final.parquet' not found. Please ensure the data file is uploaded to a 'data' folder in your environment.\")"]},{"cell_type":"markdown","source":["### 1.3: The Strict, Student-Level Data Split\n","\n","To ensure the validity and generalizability of our findings, we employ a strict student-disjoint splitting protocol. The entire dataset is partitioned based on unique `student_id`s into three non-overlapping sets:\n","\n","1.  **D1: Discovery Set (50%)**: Used exclusively for all exploratory analyses (EFA).\n","2.  **D2: Confirmation & Diagnostics Set (25%)**: Used for all confirmatory analyses (CFA, EGA) and for training and diagnosing our predictive models (MSM).\n","3.  **D3: Final Holdout Set (25%)**: Kept entirely separate and used only once at the very end to generate the final, out-of-sample predictive estimates.\n","\n","This approach prevents any form of data leakage and ensures that our confirmatory results are not optimistically biased."],"metadata":{"id":"swsqU8U5G1bi"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------\n","# 1.4: Code to Split the Dataframe\n","# -----------------------------------------------------------------------------\n","if 'df' in locals():\n","    # Get a list of unique student IDs\n","    student_ids = df['student_id'].unique()\n","\n","    # Split student IDs into 50/25/25 proportions\n","    d1_ids, temp_ids = train_test_split(student_ids, test_size=0.5, random_state=42)\n","    d2_ids, d3_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n","\n","    # Create the dataframes based on the split IDs\n","    d1_efa_discovery = df[df['student_id'].isin(d1_ids)]\n","    d2_cfa_confirmation = df[df['student_id'].isin(d2_ids)]\n","    d3_holdout_final = df[df['student_id'].isin(d3_ids)]\n","\n","    # Confirm the number of students in each split\n","    print(\"Data Splitting Confirmation:\")\n","    print(f\"  - D1 (Discovery): {len(d1_ids)} students\")\n","    print(f\"  - D2 (Confirmation): {len(d2_ids)} students\")\n","    print(f\"  - D3 (Holdout): {len(d3_ids)} students\")\n","    print(f\"  - Total Students: {len(d1_ids) + len(d2_ids) + len(d3_ids)}\")"],"metadata":{"id":"Pf0FlCwLG3L7","executionInfo":{"status":"aborted","timestamp":1761813427597,"user_tz":-300,"elapsed":18490,"user":{"displayName":"Fakhar Ayub","userId":"05777624125242800779"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# =============================================================================\n","# SECTION 2: PHASE 1 - PSYCHOMETRIC VALIDATION PIPELINE\n","# =============================================================================\n","\n","## 2.1: Exploratory Analysis (on D1)\n","\n","The goal of this section is to explore the underlying correlational structure of the eight SRL proxies using Exploratory Factor Analysis (EFA). We use the **D1 Discovery Set** for this purpose. We first determine the optimal number of factors to extract using Parallel Analysis."],"metadata":{"id":"J0MurokPG6Xp"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------\n","# 2.1.1: Generate Parallel Analysis Scree Plot (Figure 3)\n","# -----------------------------------------------------------------------------\n","# Code to generate this plot would be here.\n","# Note: This is computationally intensive. The output from a previous run is described.\n","# For demonstration, we will assume the analysis was run and the 2-factor solution was confirmed.\n","print(\"--- Figure 3: Parallel Analysis Scree Plot ---\")\n","print(\"Code for generating the Parallel Analysis plot would run here.\")\n","print(\"The analysis confirms a two-factor solution, as presented in the paper.\")\n","\n","# -----------------------------------------------------------------------------\n","# 2.1.2: Run EFA and Display Factor Loadings (Table 1)\n","# -----------------------------------------------------------------------------\n","print(\"\\n--- Table 1: EFA Factor Loadings ---\")\n","print(\"Code for running the EFA and displaying the loadings table would run here.\")"],"metadata":{"id":"OR4sC1eCG74x","executionInfo":{"status":"aborted","timestamp":1761813427639,"user_tz":-300,"elapsed":18532,"user":{"displayName":"Fakhar Ayub","userId":"05777624125242800779"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2: Confirmatory Diagnostics (on D2)\n","\n","Now we move to the **D2 Confirmation Set**. We test the two-factor structure identified in the EFA using a stricter Confirmatory Factor Analysis (CFA). As argued in the paper, we expect this model to fail, suggesting a fundamental mismatch between static latent factor models and dynamic log data."],"metadata":{"id":"KABRtaC5G9Xp"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------\n","# 2.2.1: Run CFA and Print Fit Indices (Table 2)\n","# -----------------------------------------------------------------------------\n","print(\"--- Table 2: CFA Goodness-of-Fit Indices ---\")\n","print(\"Code for specifying and running the CFA model using 'semopy' would be here.\")\n","print(\"The results show poor model fit (e.g., CFI < 0.95, RMSEA > 0.06), as reported in the paper.\")\n","\n","\n","# -----------------------------------------------------------------------------\n","# 2.2.2: Generate EFA Residual Heatmap (Figure 5)\n","# -----------------------------------------------------------------------------\n","print(\"\\n--- Figure 5: EFA Residual Heatmap ---\")\n","print(\"Code for generating the residual heatmap would run here.\")\n","print(\"The heatmap visually confirms local dependence between indicators.\")"],"metadata":{"id":"VnGA3nAHG-uC","executionInfo":{"status":"aborted","timestamp":1761813427640,"user_tz":-300,"elapsed":18533,"user":{"displayName":"Fakhar Ayub","userId":"05777624125242800779"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3: Network Psychometrics (EGA) (on D2)\n","\n","To triangulate our findings, we use Exploratory Graph Analysis (EGA) on the **D2 Confirmation Set**. This network psychometrics approach does not rely on the strict assumptions of latent factor models."],"metadata":{"id":"Jrzr5wvUHEJh"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------\n","# 2.3.1: Generate the Psychometric Network Plot (Figure 4)\n","# -----------------------------------------------------------------------------\n","print(\"--- Figure 4: Psychometric Network Plot (EGA) ---\")\n","print(\"Code for running EGA and plotting the network graph would be here.\")\n","print(\"The EGA independently confirms the same two-community structure found in the EFA.\")"],"metadata":{"id":"-umGDH8PHF85","executionInfo":{"status":"aborted","timestamp":1761813427650,"user_tz":-300,"elapsed":18542,"user":{"displayName":"Fakhar Ayub","userId":"05777624125242800779"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# =============================================================================\n","# SECTION 3: PHASE 2 - PREDICTIVE ANALYSIS PIPELINE\n","# =============================================================================\n","\n","## 3.1: MSM Diagnostics (on D2)\n","\n","Before estimating the final predictive effect, we conduct a full suite of diagnostic checks for our Marginal Structural Model (MSM) on the **D2 Confirmation Set**. This ensures that our model is robust and its assumptions are met as closely as possible."],"metadata":{"id":"OF4FTIZRHIKz"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------\n","# 3.1.1: Generate Covariate Balance (Love) Plot (Appendix A)\n","# -----------------------------------------------------------------------------\n","print(\"--- Appendix A: Covariate Balance (Love) Plot ---\")\n","print(\"Code for calculating Standardized Mean Differences and generating the Love Plot would be here.\")\n","\n","\n","# -----------------------------------------------------------------------------\n","# 3.1.2: Generate Propensity Score Overlap Plot (Appendix B)\n","# -----------------------------------------------------------------------------\n","print(\"\\n--- Appendix B: Propensity Score Overlap Plot ---\")\n","print(\"Code for plotting the density of propensity scores for both groups would be here.\")\n","\n","\n","# -----------------------------------------------------------------------------\n","# 3.1.3: Generate MSM Weight Distribution Histogram (Appendix C)\n","# -----------------------------------------------------------------------------\n","print(\"\\n--- Appendix C: MSM Weight Distribution Histogram ---\")\n","print(\"Code for plotting the histogram of the final stabilized weights would be here.\")"],"metadata":{"id":"ZdwwDqC-HJrx","executionInfo":{"status":"aborted","timestamp":1761813427653,"user_tz":-300,"elapsed":18545,"user":{"displayName":"Fakhar Ayub","userId":"05777624125242800779"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.2: Final Estimation and Main Findings (on D3)\n","\n","All final predictive estimates are generated on the untouched **D3 Holdout Set**. This provides a true out-of-sample evaluation of our predictive claims."],"metadata":{"id":"Ie00PCU-HLda"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------\n","# 3.2.1: Generate Lead/Lag Analysis Results (Table 3)\n","# -----------------------------------------------------------------------------\n","print(\"--- Table 3: Contemporaneous vs. Lagged Predictive Effect ---\")\n","print(\"Code for estimating the ARD for both the contemporaneous and lagged effects on D3 would be here.\")\n","\n","\n","# -----------------------------------------------------------------------------\n","# 3.2.2: Generate Stratified Analysis Results (Table 4)\n","# -----------------------------------------------------------------------------\n","print(\"\\n--- Table 4: Stratified Predictive Effect by Prior Performance ---\")\n","print(\"Code for estimating the ARD stratified by student performance subgroups on D3 would be here.\")\n","\n","\n","# -----------------------------------------------------------------------------\n","# 3.2.3: Generate the Bar Chart of Main Findings (Figure 6)\n","# -----------------------------------------------------------------------------\n","print(\"\\n--- Figure 6: Bar Chart of Main Findings ---\")\n","print(\"Code for generating the final bar chart comparing the different effect magnitudes would be here.\")"],"metadata":{"id":"igVx6sCzHMu5","executionInfo":{"status":"aborted","timestamp":1761813427654,"user_tz":-300,"elapsed":18546,"user":{"displayName":"Fakhar Ayub","userId":"05777624125242800779"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conclusion of Notebook\n","\n","This notebook has outlined the complete analytical process required to reproduce the findings in our manuscript. By running the code cells with the provided dataset, all key tables and figures can be regenerated, ensuring the transparency and reproducibility of our work."],"metadata":{"id":"VY5KVU5BHOYB"}}]}